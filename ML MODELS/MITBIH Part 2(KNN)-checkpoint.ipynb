{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import percentile\n",
    "from numpy.random import rand    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the mitbih data set\n",
    "test = pd.read_csv(\"mitbih_test.csv\", header=None)\n",
    "train = pd.read_csv(\"mitbih_train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the feature 0, No of Outliers is 12161\n",
      "For the feature 1, No of Outliers is 5575\n",
      "For the feature 2, No of Outliers is 0\n",
      "For the feature 3, No of Outliers is 1786\n",
      "For the feature 4, No of Outliers is 6596\n"
     ]
    }
   ],
   "source": [
    "#Fining the outliers\n",
    "continous_features =   train[187].unique()\n",
    "def outliers(df_out, drop = False):\n",
    "    for each_feature in df_out.columns:\n",
    "        feature_data = df_out[each_feature]\n",
    "        Q1 = np.percentile(feature_data, 25.) # 25th percentile of the data of the given feature\n",
    "        Q3 = np.percentile(feature_data, 75.) # 75th percentile of the data of the given feature\n",
    "        IQR = Q3-Q1 \n",
    "        outlier_step = IQR * 1.5 \n",
    "        outliers = feature_data[~((feature_data >= Q1 - outlier_step) & (feature_data <= Q3 + outlier_step))].index.tolist()  \n",
    "        if not drop:\n",
    "            print('For the feature {}, No of Outliers is {}'.format(each_feature, len(outliers)))\n",
    "        if drop:\n",
    "            train.drop(outliers, inplace = True, errors = 'ignore')\n",
    "            print('Outliers from {} feature removed'.format(each_feature))\n",
    "outliers(train[continous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers from 0 feature removed\n",
      "Outliers from 1 feature removed\n",
      "Outliers from 2 feature removed\n",
      "Outliers from 3 feature removed\n",
      "Outliers from 4 feature removed\n"
     ]
    }
   ],
   "source": [
    "#Removing the outliers\n",
    "outliers(train[continous_features], drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Resampling and building the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "train_lbl0 = resample(train[train[187]==0], replace=True, n_samples=15000, random_state=113)\n",
    "train_lbl1 = resample(train[train[187]==1], replace=True, n_samples=15000, random_state=113)\n",
    "train_lbl2 = resample(train[train[187]==2], replace=True, n_samples=15000, random_state=113)\n",
    "train_lbl3 = resample(train[train[187]==3], replace=True, n_samples=15000, random_state=113)\n",
    "train_lbl4 = resample(train[train[187]==4], replace=True, n_samples=15000, random_state=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in each label: \n",
      "4    15000\n",
      "3    15000\n",
      "2    15000\n",
      "1    15000\n",
      "0    15000\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train= pd.concat([train_lbl0, train_lbl1, train_lbl2, train_lbl3, train_lbl4])\n",
    "labels = train[187].astype('int64') # last column has the labels\n",
    "print(\"Count in each label: \")\n",
    "print(labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, : -1].values\n",
    "y_train = train.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.iloc[:, : -1].values\n",
    "y_test = test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.88453609 0.61237115 ... 0.         0.         0.        ]\n",
      " [1.         0.8888889  0.52430558 ... 0.         0.         0.        ]\n",
      " [0.91666669 0.76234567 0.36419752 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [1.         0.47955391 0.52788103 ... 0.         0.         0.        ]\n",
      " [1.         0.47569445 0.50347221 ... 0.         0.         0.        ]\n",
      " [1.         0.6736111  0.4212963  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75826448 0.11157025 ... 0.         0.         0.        ]\n",
      " [0.90842491 0.7838828  0.53113556 ... 0.         0.         0.        ]\n",
      " [0.73008847 0.21238938 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [1.         0.96735907 0.62017804 ... 0.         0.         0.        ]\n",
      " [0.98412699 0.5674603  0.60714287 ... 0.         0.         0.        ]\n",
      " [0.97396964 0.91323209 0.86550975 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.62965712  0.40540237  0.52082393 ... -0.15798999 -0.15650701\n",
      "  -0.15550876]\n",
      " [ 0.62965712  0.43406513  0.10498512 ... -0.15798999 -0.15650701\n",
      "  -0.15550876]\n",
      " [-0.88616344 -0.39920815 -0.6510328  ... -0.15798999 -0.15650701\n",
      "  -0.15550876]\n",
      " ...\n",
      " [ 0.62965712 -2.26136095  0.12186809 ... -0.15798999 -0.15650701\n",
      "  -0.15550876]\n",
      " [ 0.62965712 -2.28677508  0.00661154 ... -0.15798999 -0.15650701\n",
      "  -0.15550876]\n",
      " [ 0.62965712 -0.98351556 -0.38141678 ... -0.15798999 -0.15650701\n",
      "  -0.15550876]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.45017238 -0.01663683 -1.37839723 ... -0.08819499 -0.08446082\n",
      "  -0.0835278 ]\n",
      " [ 0.05975141  0.10052673  0.45723507 ... -0.08819499 -0.08446082\n",
      "  -0.0835278 ]\n",
      " [-0.70056768 -2.51315818 -1.86652611 ... -0.08819499 -0.08446082\n",
      "  -0.0835278 ]\n",
      " ...\n",
      " [ 0.45017238  0.93964253  0.84680317 ... -0.08819499 -0.08446082\n",
      "  -0.0835278 ]\n",
      " [ 0.38249941 -0.88926633  0.78977321 ... -0.08819499 -0.08446082\n",
      "  -0.0835278 ]\n",
      " [ 0.33919461  0.69209661  1.92014929 ... -0.08819499 -0.08446082\n",
      "  -0.0835278 ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(sc.transform([[9.60E-01,8.63E-01,4.62E-01,1.97E-01,9.40E-02,1.25E-01,9.97E-02,8.83E-02,7.41E-02,8.26E-02,7.41E-02,6.27E-02,6.55E-02,6.55E-02,6.27E-02,7.69E-02,7.12E-02,8.26E-02,9.12E-02,9.69E-02,8.26E-02,8.26E-02,9.12E-02,1.05E-01,1.23E-01,1.48E-01,1.82E-01,1.94E-01,2.14E-01,2.08E-01,2.22E-01,2.54E-01,2.71E-01,2.88E-01,2.85E-01,2.93E-01,2.56E-01,2.48E-01,1.88E-01,1.45E-01,1.08E-01,8.26E-02,7.98E-02,7.41E-02,1.42E-02,1.14E-02,6.27E-02,5.13E-02,5.70E-02,4.84E-02,2.85E-02,3.13E-02,7.69E-02,2.56E-02,2.85E-02,3.70E-02,9.40E-02,8.55E-02,3.99E-02,5.98E-02,7.41E-02,7.98E-02,9.12E-02,9.97E-02,1.08E-01,8.83E-02,9.12E-02,6.55E-02,8.83E-02,7.69E-02,8.26E-02,9.69E-02,9.97E-02,1.34E-01,1.03E-01,3.99E-02,6.55E-02,7.41E-02,8.26E-02,8.55E-02,5.70E-02,4.56E-02,1.03E-01,3.99E-02,1.14E-02,1.71E-02,3.13E-02,5.70E-03,8.55E-03,3.13E-02,5.13E-02,5.70E-02,8.83E-02,6.55E-02,1.14E-02,5.70E-02,3.99E-02,3.99E-02,2.56E-02,2.85E-03,1.99E-02,2.56E-02,1.14E-02,2.85E-02,1.99E-02,2.28E-02,3.42E-02,1.42E-02,5.13E-02,6.84E-02,1.40E-01,2.88E-01,5.27E-01,7.78E-01,1.00E+00,8.89E-01,4.93E-01,1.91E-01,8.83E-02,6.27E-02,3.42E-02,0.00E+00,3.42E-02,1.71E-02,2.85E-03,0.00E+00,4.84E-02,4.84E-02,5.41E-02,4.27E-02,5.41E-02,5.98E-02,6.27E-02,7.12E-02,7.69E-02,9.97E-02,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00,0.00E+00]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " ...\n",
      " [4. 4.]\n",
      " [4. 4.]\n",
      " [4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15306   969  1060   583   200]\n",
      " [   90   422    32     7     5]\n",
      " [  180   103  1074    46    45]\n",
      " [    5     2    18   135     2]\n",
      " [   25    11    28     2  1542]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8440983007491321"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.84      0.91     18118\n",
      "         1.0       0.28      0.76      0.41       556\n",
      "         2.0       0.49      0.74      0.59      1448\n",
      "         3.0       0.17      0.83      0.29       162\n",
      "         4.0       0.86      0.96      0.91      1608\n",
      "\n",
      "    accuracy                           0.84     21892\n",
      "   macro avg       0.56      0.83      0.62     21892\n",
      "weighted avg       0.92      0.84      0.87     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
