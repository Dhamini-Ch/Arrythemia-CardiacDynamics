{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RawB2GktBQFs",
        "outputId": "792b885d-6571-4ebd-eae9-06c0b85f142f"
      },
      "id": "RawB2GktBQFs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789a890b",
      "metadata": {
        "id": "789a890b"
      },
      "outputs": [],
      "source": [
        "#Importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e88669c",
      "metadata": {
        "id": "8e88669c"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datafiles/combined_train.csv\", header=None)\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/datafiles/combined_test.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fzOBhzlnr0m",
        "outputId": "a40f8d3f-7901-4eb2-c5eb-238f807edd6b"
      },
      "id": "-fzOBhzlnr0m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98466, 188)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-V8em4gnuLD",
        "outputId": "885a9997-e081-4a7a-f909-375cbc9dee03"
      },
      "id": "j-V8em4gnuLD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25531, 188)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686783d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "686783d3",
        "outputId": "e559499d-aa0c-45d5-87e0-12e3f7bfa11e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Finding the number of classes in the datset\n",
        "train[187].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the number of classes in the datset\n",
        "test[187].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ma3K8ENnx6q",
        "outputId": "32e9f0fe-045d-4c37-827d-2ebb95818ad5"
      },
      "id": "-ma3K8ENnx6q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.utils import resample\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "train_lbl0 = resample(train[train[187]==0], replace=True, n_samples=15000, random_state=113)\n",
        "train_lbl1 = resample(train[train[187]==1], replace=True, n_samples=15000, random_state=113)\n",
        "train_lbl2 = resample(train[train[187]==2], replace=True, n_samples=15000, random_state=113)\n",
        "train_lbl3 = resample(train[train[187]==3], replace=True, n_samples=15000, random_state=113)\n",
        "train_lbl4 = resample(train[train[187]==4], replace=True, n_samples=15000, random_state=113)\n",
        "train_lbl5 = resample(train[train[187]==5], replace=True, n_samples=15000, random_state=113)\n",
        "train_lbl6 = resample(train[train[187]==6], replace=True, n_samples=15000, random_state=113)"
      ],
      "metadata": {
        "id": "yDWoVW-vwgVB"
      },
      "id": "yDWoVW-vwgVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train= pd.concat([train_lbl0, train_lbl1, train_lbl2, train_lbl3, train_lbl4, train_lbl5, train_lbl6])\n",
        "\n",
        "labels = train[187].astype('int64')   # last column has the labels\n",
        "\n",
        "print(\"Count in each label: \")\n",
        "print(labels.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ9_71yTwgRa",
        "outputId": "c7ca3ea1-65aa-4292-a3df-60cf35ae917f"
      },
      "id": "RQ9_71yTwgRa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count in each label: \n",
            "0    15000\n",
            "1    15000\n",
            "2    15000\n",
            "3    15000\n",
            "4    15000\n",
            "5    15000\n",
            "6    15000\n",
            "Name: 187, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Fining the outliers\n",
        "# continous_features =   train[187].unique()\n",
        "# def outliers(df_out, drop = False):\n",
        "#     for each_feature in df_out.columns:\n",
        "#         feature_data = df_out[each_feature]\n",
        "#         Q1 = np.percentile(feature_data, 25.) # 25th percentile of the data of the given feature\n",
        "#         Q3 = np.percentile(feature_data, 75.) # 75th percentile of the data of the given feature\n",
        "#         IQR = Q3-Q1 \n",
        "#         outlier_step = IQR * 1.5 \n",
        "#         outliers = feature_data[~((feature_data >= Q1 - outlier_step) & (feature_data <= Q3 + outlier_step))].index.tolist()  \n",
        "#         if not drop:\n",
        "#             print('For the feature {}, No of Outliers is {}'.format(each_feature, len(outliers)))\n",
        "#         if drop:\n",
        "#             train.drop(outliers, inplace = True, errors = 'ignore')\n",
        "#             print('Outliers from {} feature removed'.format(each_feature))\n",
        "# outliers(train[continous_features])"
      ],
      "metadata": {
        "id": "pY0JuRz3wgO_"
      },
      "id": "pY0JuRz3wgO_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Removing the outliers\n",
        "# outliers(train[continous_features], drop=True)"
      ],
      "metadata": {
        "id": "SOwCsPU_IqCX"
      },
      "id": "SOwCsPU_IqCX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Fining the outliers\n",
        "# continous_features =   test[187].unique()\n",
        "# def outliers(df_out, drop = False):\n",
        "#     for each_feature in df_out.columns:\n",
        "#         feature_data = df_out[each_feature]\n",
        "#         Q1 = np.percentile(feature_data, 25.) # 25th percentile of the data of the given feature\n",
        "#         Q3 = np.percentile(feature_data, 75.) # 75th percentile of the data of the given feature\n",
        "#         IQR = Q3-Q1 \n",
        "#         outlier_step = IQR * 1.5 \n",
        "#         outliers = feature_data[~((feature_data >= Q1 - outlier_step) & (feature_data <= Q3 + outlier_step))].index.tolist()  \n",
        "#         if not drop:\n",
        "#             print('For the feature {}, No of Outliers is {}'.format(each_feature, len(outliers)))\n",
        "#         if drop:\n",
        "#             test.drop(outliers, inplace = True, errors = 'ignore')\n",
        "#             print('Outliers from {} feature removed'.format(each_feature))\n",
        "# outliers(test[continous_features])"
      ],
      "metadata": {
        "id": "sLsgnbY9Ip-2"
      },
      "id": "sLsgnbY9Ip-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Removing the outliers\n",
        "# outliers(test[continous_features], drop=True)"
      ],
      "metadata": {
        "id": "CD_d8Q0fIp9T"
      },
      "id": "CD_d8Q0fIp9T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19b23fc",
      "metadata": {
        "id": "b19b23fc"
      },
      "outputs": [],
      "source": [
        "#Feature Scaling\n",
        "x_train = train.iloc[:, :-1].values\n",
        "y_train = train.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b346f79",
      "metadata": {
        "id": "4b346f79"
      },
      "outputs": [],
      "source": [
        "#Feature Scaling\n",
        "x_test = test.iloc[:, :-1].values\n",
        "y_test = test.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ad9ad5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ad9ad5",
        "outputId": "40ba3209-136a-4bbd-c3df-967ac033ef4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25531, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#Dimminsion of the dataset\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cfe3c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3cfe3c0",
        "outputId": "6475cf57-59a6-4f46-b1e8-847bb0b6fb18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25531,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#Diminsion of the dataset\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AdaBoost**"
      ],
      "metadata": {
        "id": "KzwxAyuprQ_O"
      },
      "id": "KzwxAyuprQ_O"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "max_estimators = 100\n",
        "ada_boost = AdaBoostClassifier(RandomForestClassifier(max_depth = 1, # Just a stump.\n",
        "                                      random_state = np.random.RandomState(0)),\n",
        "                               n_estimators = max_estimators,\n",
        "                               random_state = np.random.RandomState(0))\n",
        "\n",
        "# Fit all estimators.\n",
        "ada_boost.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "Gl8-fdmVqJrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad30e0d-b20a-4638-d8cb-0ff36a62a6b3"
      },
      "id": "Gl8-fdmVqJrS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=1,\n",
              "                                                         random_state=RandomState(MT19937) at 0x7F757AC18490),\n",
              "                   n_estimators=100,\n",
              "                   random_state=RandomState(MT19937) at 0x7F757AC188D0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ada_boost.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "G8tiz71GoylF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0833ec3-d368-4764-a613-c95f9c3340a8"
      },
      "id": "G8tiz71GoylF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47150522893737024"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oQvqqomFbi3l"
      },
      "id": "oQvqqomFbi3l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Ada boost_MITBIH and PTBDB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}